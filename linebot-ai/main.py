from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (MessageEvent, TextMessage, TextSendMessage,
                            ImageMessage, AudioMessage, VideoSendMessage, FlexSendMessage)
import os
import re
import base64
import datetime
import pyodbc
from pydub import AudioSegment
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
from io import BytesIO

load_dotenv()

# âœ… LINE æ†‘è­‰ï¼ˆè«‹å‹¿å¤–æ´©ï¼‰
LINE_CHANNEL_ACCESS_TOKEN = 'LpZLSJAqLsv3weSWeP4OgFuB2rAFgIOAR2RjZ/X4el1cIl3vLExeq6gU1iK08QaMNdj0pj3L51RohY50Re+d+6jhS7CVZwxcdl815P0tfcsofyiabYBRURAgW28phLDAOOWL8+6ijNuV7zHZ8qYMRQdB04t89/1O/w1cDnyilFU='
LINE_CHANNEL_SECRET = '3db04cf933e7e95d73e2666867203573'
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# GPT client
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_API_BASE")
)

flex_message_json = {
  "type": "bubble",
  "header": {
    "type": "box",
    "layout": "vertical",
    "contents": [
      {
        "type": "text",
        "text": "å ±ä¿®å¹³å°",
        "color": "#000000",
        "weight": "bold"
      }
    ]
  },
  "body": {
    "type": "box",
    "layout": "vertical",
    "spacing": "sm",
    "paddingAll": "10px",
    "contents": [
      {
        "type": "box",
        "layout": "horizontal",
        "spacing": "sm",
        "contents": [
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "ç³»çµ±",
              "text": "ç³»çµ±"
            }
          },
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "è¢å¹•",
              "text": "è¢å¹•"
            }
          }
        ]
      },
      {
        "type": "box",
        "layout": "horizontal",
        "spacing": "sm",
        "contents": [
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "ç›¤é»æ©Ÿ",
              "text": "ç›¤é»æ©Ÿ"
            }
          },
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "ç¶²è·¯",
              "text": "ç¶²è·¯"
            }
          }
        ]
      },
      {
        "type": "box",
        "layout": "horizontal",
        "spacing": "sm",
        "contents": [
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "å¹³æ¿",
              "text": "å¹³æ¿"
            }
          },
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "é›»è©±",
              "text": "é›»è©±"
            }
          }
        ]
      },
      {
        "type": "box",
        "layout": "horizontal",
        "spacing": "sm",
        "contents": [
          {
            "type": "button",
            "height": "sm",
            "style": "primary",
            "color": "#C0C0C0",
            "action": {
              "type": "message",
              "label": "åˆ—å°",
              "text": "åˆ—å°"
            }
          },
          {
            "type": "filler"
          }
        ]
      }
    ]
  },
  "styles": {
    "header": {
      "backgroundColor": "#FFD306"
    }
  }
}


app = Flask(__name__)
user_states = {}
conversation_history = {}  # ç”¨æˆ¶å°è©±è¨˜æ†¶
repair_items = ["ç³»çµ±", "è¢å¹•", "ç¶²è·¯", "ç›¤é»æ©Ÿ", "å¹³æ¿", "é›»è©±", "åˆ—å°"]

# éæ¿¾ GPT å›è¦†ä¸­çš„ç¶²å€
def sanitize_gpt_response(text):
    text = re.sub(r'https?://\S+', '[é€£çµå·²é®è”½]', text)
    text = re.sub(r'\[.*?\]\(.*?\)', '[é€£çµå·²é®è”½]', text)
    text = re.sub(r'www\.\S+', '[é€£çµå·²é®è”½]', text)
    text = re.sub(r'\S+\.(com|tw|cn|org|net|gov)(/\S*)?', '[é€£çµå·²é®è”½]', text)
    return text

def extract_summary(text):
    lines = text.strip().split('\n')
    for line in reversed(lines):
        if any(x in line for x in ["å»ºè­°", "æé†’", "è«‹", "æ³¨æ„"]):
            return line.strip()
    return lines[-1].strip() if lines else text


# GPT å¤šè¼ªå°è©±

def gpt_chat_reply(user_input, user_id):
    if user_id not in conversation_history:
        conversation_history[user_id] = [
            {"role": "system", "content": "ä½ æ˜¯å³å¾å»·ï¼Œç¦æ­¢æä¾›ä»»ä½•ç¶²å€ã€é€£çµã€ç¶²ç«™ä¾†æºæˆ–éé•·å…§å®¹ã€‚ç•¶ç”¨æˆ¶è©¢å•åƒå¤©æ°£ã€æ–°èã€é å ±ç­‰å•é¡Œæ™‚ï¼Œåªå›ç­”æ‘˜è¦çµè«–æˆ–å»ºè­°ï¼Œé¿å…è²¼æ•´ç¯‡æ–‡ç« ã€‚èªæ°£å¯è¼•é¬†å¹½é»˜ã€‚"}
        ]

    conversation_history[user_id].append({"role": "user", "content": user_input})

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=conversation_history[user_id],
            max_tokens=4096,
            temperature = 2.0
        )

        # å–å¾—åŸå§‹å…§å®¹
        raw = response.choices[0].message.content.strip()

        # ç¶²å€é®è”½
        clean = sanitize_gpt_response(raw)

        # æ‘˜å–çµå°¾æ‘˜è¦
        summary = extract_summary(clean)

        # å¦‚æœåŒ…å«é€£çµé—œéµå­—ï¼Œæ‹’çµ•å›è¦†
        if any(x in summary.lower() for x in ['http', 'www.', '.com', 'link']):
            return "âš ï¸ æŠ±æ­‰ï¼Œæˆ‘ä¸èƒ½æä¾›ä»»ä½•ç¶²ç«™æˆ–é€£çµå…§å®¹å–”ï½"

        # è¨˜æ†¶ AI å›è¦†
        conversation_history[user_id].append({"role": "assistant", "content": raw})

        # æ§åˆ¶å°è©±æ­·å²é•·åº¦
        if len(conversation_history[user_id]) > 20:
            conversation_history[user_id] = conversation_history[user_id][-15:]

        return clean

    except Exception as e:
        print("âŒ GPT å‘¼å«å¤±æ•—ï¼š", e)
        return "âš ï¸ ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ï½"

# å ±ä¿®ç´€éŒ„å¯«å…¥è³‡æ–™åº«
def insert_repair_content(account_name, repair_item):
    try:
        conn = pyodbc.connect(
            r'DRIVER={SQL Server};SERVER=.\SQLEXPRESS;DATABASE=RepairTrackDB;Trusted_Connection=yes;')
        with conn.cursor() as cursor:
            insert_query = """
                INSERT INTO dbo.RepairContents (Account, RC_ID, RepairSolve_Note, RepairTime, Status)
                VALUES (?, ?, ?, ?, ?)
            """
            now = datetime.datetime.now()
            cursor.execute(insert_query, (account_name, None, repair_item, now, 'å¾…è™•ç†'))
            conn.commit()
            return True
    except Exception as e:
        print("âŒ å¯«å…¥å¤±æ•—ï¼š", e)
        return False
    finally:
        if 'conn' in locals():
            conn.close()

# æ–‡å­—è¨Šæ¯è™•ç†
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    user_id = event.source.user_id
    text = event.message.text.strip()
    state = user_states.get(user_id)

    if text == "å ±ä¿®":
        user_states[user_id] = {"state": "WAITING_FOR_STORE_CODE"}
        reply = TextSendMessage(text="è«‹è¼¸å…¥åº—æ«ƒç·¨è™Ÿ")

    elif isinstance(state, dict) and state.get("state") == "WAITING_FOR_STORE_CODE":
        try:
            conn = pyodbc.connect(r'DRIVER={SQL Server};SERVER=.\SQLEXPRESS;DATABASE=RepairTrackDB;Trusted_Connection=yes;')
            with conn.cursor() as cursor:
                cursor.execute("SELECT Counter_Number FROM dbo.Counter WHERE Counter_Code = ?", (text,))
                row = cursor.fetchone()
                if row:
                    account_name = row[0]
                    user_states[user_id] = {
                        "state": "WAITING_FOR_FAULT_SELECTION",
                        "store_code": text,
                        "account_name": account_name
                    }
                    reply = FlexSendMessage(alt_text="è«‹é¸æ“‡å ±ä¿®é …ç›®", contents=flex_message_json)
                else:
                    reply = TextSendMessage(text="âŒ æŸ¥ç„¡æ­¤åº—æ«ƒç·¨è™Ÿï¼Œè«‹é‡æ–°è¼¸å…¥")
        except Exception as e:
            print("âŒ æŸ¥è©¢éŒ¯èª¤ï¼š", e)
            reply = TextSendMessage(text="âš  æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦")
        finally:
            if 'conn' in locals(): conn.close()

    elif isinstance(state, dict) and state.get("state") == "WAITING_FOR_FAULT_SELECTION":
        if text in repair_items:
            account_name = state.get("account_name")
            success = insert_repair_content(account_name, text)
            reply = TextSendMessage(text=f"âœ… å·²å®Œæˆã€Œ{text}ã€é …ç›®çš„å ±ä¿®ç™»è¨˜ï¼ˆ{account_name}ï¼‰")
            user_states.pop(user_id, None)
        else:
            reply = TextSendMessage(text="è«‹å¾é¸å–®ä¸­é»é¸æœ‰æ•ˆå ±ä¿®é …ç›®ã€‚")

    elif text == "æ¸…é™¤è¨˜æ†¶":
        conversation_history.pop(user_id, None)
        reply = TextSendMessage(text="ğŸ§¹ å·²æ¸…é™¤è¨˜æ†¶ã€‚æ‚¨å¯ä»¥é‡æ–°é–‹å§‹æå•ã€‚")

    else:
        gpt_reply = gpt_chat_reply(text, user_id)
        reply = TextSendMessage(text=gpt_reply)

    line_bot_api.reply_message(event.reply_token, reply)

# åœ–ç‰‡è™•ç† + GPT Vision
@handler.add(MessageEvent, message=ImageMessage)
def handle_image(event):
    message_id = event.message.id
    image_content = line_bot_api.get_message_content(message_id).content

    with open("../temp.jpg", "wb") as f:
        f.write(image_content)

    with open("../temp.jpg", "rb") as image_file:
        image_data = base64.b64encode(image_file.read()).decode("utf-8")

    image_input = {
        "type": "image_url",
        "image_url": {
            "url": f"data:image/jpeg;base64,{image_data}"
        }
    }

    try:
        response = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": "è«‹èªªæ˜é€™å¼µåœ–ç‰‡çš„å…§å®¹ï¼Œå”åŠ©åˆ¤æ–·å…¶ç”¨é€”æˆ–éŒ¯èª¤è¨Šæ¯ã€‚"},
                    image_input
                ]}
            ],
            max_tokens=500
        )
        gpt_result = response.choices[0].message.content.strip()
    except Exception as e:
        print("âŒ GPT åœ–åƒåˆ†æå¤±æ•—ï¼š", e)
        gpt_result = "âš ï¸ åœ–åƒ AI åˆ†æå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ï½"

    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=gpt_result))

# èªéŸ³è¨Šæ¯è™•ç†ï¼ˆWhisper æ¨¡å¼ï¼‰
@handler.add(MessageEvent, message=AudioMessage)
def handle_audio(event):
    message_id = event.message.id
    audio_content = line_bot_api.get_message_content(message_id).content
    with open("temp.m4a", "wb") as f:
        f.write(audio_content)
    AudioSegment.from_file("temp.m4a").export("temp.wav", format="wav")

    recognizer = sr.Recognizer()
    with sr.AudioFile("temp.wav") as source:
        audio = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio, language="zh-TW")
        except:
            text = "âŒ èªéŸ³ç„¡æ³•è¾¨è­˜"

    user_id = event.source.user_id
    gpt_reply = gpt_chat_reply(text, user_id)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=gpt_reply))

# å•Ÿå‹•ä¼ºæœå™¨
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

if __name__ == "__main__":
    app.run()